# video_summary/views.py
import os
import requests
import json
import logging
import uuid
import csv
import string
from datetime import datetime
from google import genai
from google.genai import types
import google.generativeai as legacy_genai  # For legacy functions
from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound
from django.http import JsonResponse, HttpResponse
from django.shortcuts import render
from dotenv import load_dotenv
from utils.supabase_client import save_to_supabase
from django.views.decorators.csrf import csrf_exempt
from django.middleware.csrf import get_token

logger = logging.getLogger(__name__)

# Create a simple home view for the root URL
def home(request):
    return HttpResponse("Welcome to SuperMind!")

load_dotenv()

# Set up Google Gemini client with API key
API_KEY = os.getenv("api_key1")
client = genai.Client(api_key=API_KEY)

# Configure legacy genai for backward compatibility
legacy_genai.configure(api_key=API_KEY)

# Function to convert a number to Base62 (shortened ID)
def to_base62(num):
    base62_chars = string.ascii_letters + string.digits  # A-Z, a-z, 0-9
    if num == 0:
        return base62_chars[0]
    base62_str = []
    while num > 0:
        base62_str.append(base62_chars[num % 62])
        num = num // 62
    return ''.join(reversed(base62_str))

# Function to generate a shorter ID using Base62 encoding
def generate_short_id():
    uuid_int = uuid.uuid4().int
    return to_base62(uuid_int)[:8]  # Shorten to the first 8 characters


# Set up YouTube Data API
YOUTUBE_API_KEY = "AIzaSyCMAy4vjJ4nfGcKy-99WMoK5jwAmJswLVA"
YOUTUBE_API_URL = "https://www.googleapis.com/youtube/v3/"

# Fetch YouTube video details function
def fetch_youtube_details(video_id):
    try:
        video_details_url = f"{YOUTUBE_API_URL}videos?part=snippet,contentDetails&id={video_id}&key={YOUTUBE_API_KEY}"
        video_details_response = requests.get(video_details_url)
        video_details = video_details_response.json()

        if "items" not in video_details:
            return None, None, None, None

        video_item = video_details["items"][0]
        title = video_item["snippet"]["title"]
        channel_name = video_item["snippet"].get("channelTitle", "")
        category_id = video_item["snippet"]["categoryId"]
        
        # Get HQ720 thumbnail with fallbacks
        thumbnails = video_item["snippet"]["thumbnails"]
        thumbnail_url = (
            thumbnails.get("maxres", {}).get("url") or  # Try maxres first
            f"https://i.ytimg.com/vi/{video_id}/hq720.jpg" or  # Try direct HQ720
            thumbnails.get("high", {}).get("url") or  # Fallback to high
            thumbnails.get("medium", {}).get("url") or  # Further fallback
            ""  # Empty if nothing found
        )

        category_url = f"{YOUTUBE_API_URL}videoCategories?part=snippet&id={category_id}&key={YOUTUBE_API_KEY}"
        category_response = requests.get(category_url)
        category_data = category_response.json()
        video_type = category_data["items"][0]["snippet"]["title"]

        return title, channel_name, video_type, thumbnail_url

    except Exception as e:
        print(f"Error fetching YouTube details: {e}")
        return None, None, None, None

# Function to extract transcript details from YouTube using improved logic
def get_youtube_transcript(video_id: str, preferred_languages=['en-IN', 'en', 'mr', 'hi']) -> list:
    try:
        print(f"üîç Listing transcripts for video ID: {video_id}")
        transcripts = YouTubeTranscriptApi.list_transcripts(video_id)

        for t in transcripts:
            print(f"  - Language: {t.language} ({t.language_code}), Auto: {t.is_generated}")

        # Try manual transcripts in preferred languages first (en-IN, English, Marathi, Hindi)
        for lang in preferred_languages:
            try:
                manual = transcripts.find_manually_created_transcript([lang])
                print(f"‚úÖ Found manual transcript in: {manual.language_code}")
                return manual.fetch()
            except NoTranscriptFound:
                continue

        # Fallback to any manual transcript
        for t in transcripts:
            if not t.is_generated:
                print(f"‚úÖ Found manual transcript in: {t.language_code} (fallback)")
                return t.fetch()

        # Try autogenerated transcripts in preferred languages (en-IN, English, Marathi, Hindi)
        for lang in preferred_languages:
            try:
                auto = transcripts.find_generated_transcript([lang])
                print(f"‚úÖ Found auto-generated transcript in: {auto.language_code}")
                return auto.fetch()
            except NoTranscriptFound:
                continue

        # Fallback to any autogenerated transcript
        for t in transcripts:
            if t.is_generated:
                print(f"‚úÖ Found auto-generated transcript in: {t.language_code} (final fallback)")
                return t.fetch()

        print("‚ùå No transcript available.")
        return []

    except Exception as e:
        print(f"‚ùå Error getting transcript: {e}")
        return []

def transcript_to_text(transcript_data: list) -> str:
    # Support both dicts and objects
    texts = []
    for entry in transcript_data:
        if isinstance(entry, dict):
            texts.append(entry.get('text', ''))
        else:
            texts.append(getattr(entry, 'text', ''))
    return " ".join(texts)

# Legacy function for backward compatibility
def extract_transcript_details(youtube_video_url):
    try:
        # Simplified URL parsing for all formats
        if 'youtu.be' in youtube_video_url:
            video_id = youtube_video_url.split('/')[-1].split('?')[0]
        elif '/shorts/' in youtube_video_url:
            video_id = youtube_video_url.split('/shorts/')[-1].split('?')[0]
        elif 'v=' in youtube_video_url:
            video_id = youtube_video_url.split("v=")[1].split("&")[0]
        else:
            # For other possible YouTube URL formats
            video_id = youtube_video_url.split("/")[-1].split("?")[0]
            
        transcript_data = get_youtube_transcript(video_id)
        return transcript_to_text(transcript_data)
    except NoTranscriptFound as e:
        logger.error(f"No transcript found for video {video_id}: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"Error extracting transcript for video {video_id}: {str(e)}")
        return None

# Function to generate summary using new Gemini 2.5 Flash with video understanding
def generate_summary_with_video(video_id: str, transcript_text: str) -> str:
    try:
        contents = [
            types.Part(file_data=types.FileData(file_uri=f"https://www.youtube.com/watch?v={video_id}"))
        ]

        if transcript_text:
            contents.append(types.Part(text=transcript_text))

        prompt = "Summarize this YouTube video in 7-8 lines with maximum context using both the video and transcript if available. get the best context from both. and give the best summary possible."
        contents.append(types.Part(text=prompt))

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=types.Content(parts=contents)
        )
        return response.text

    except Exception as e:
        print(f"‚ùå Error generating summary: {e}")
        return "Error generating summary."

# Legacy function for backward compatibility
def generate_summary(content):
    try:
        if not content:
            return "No content available."
        model = legacy_genai.GenerativeModel(model_name="gemini-1.5-flash")
        response = model.generate_content(f"Summarize this text in maximum 7-8 lines:\n\n{content}")
        summary = response.text if hasattr(response, 'text') else 'Error generating summary.'
        return summary
    except Exception as e:
        return "Error generating summary."

# Function to generate tags using new Gemini client
def generate_tags_with_video(video_id: str, transcript_text: str) -> list:
    try:
        if not transcript_text:
            return []
        
        contents = [
            types.Part(file_data=types.FileData(file_uri=f"https://www.youtube.com/watch?v={video_id}"))
        ]

        if transcript_text:
            contents.append(types.Part(text=transcript_text))

        prompt = '''Generate 50 keywords/tags in English from this video and transcript. Generate a list of 50 relevant tags based on the content. 
                   don't say anything in start of response like "Sure, here is a list of 30 relevant tags for the video:" 
                   or after response ends directly write tags and nothing else. 
                   i want them in this format strictly: tag1, tag2, tag3, tag4....'''
        contents.append(types.Part(text=prompt))

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=types.Content(parts=contents)
        )
        tags = response.text.split(",") if hasattr(response, 'text') else []
        return [tag.strip() for tag in tags if tag.strip()]
    except Exception as e:
        print(f"‚ùå Error generating tags: {e}")
        return []

# Legacy function for backward compatibility
def generate_tags(content):
    try:
        if not content:
            return []
        model = legacy_genai.GenerativeModel(model_name="gemini-1.5-flash")
        response = model.generate_content(f'''Generate 50 keywords/tags in English from this text Generate a list of 50 relevant tags based on the text. 
                                          don't say anything in start of response like "Sure, here is a list of 30 relevant tags for the video:" 
                                          or after response ends directly write tags and nothing else. 
                                          i want them in this format strictly: tag1, tag2, tag3, tag4....:\n\n{content}''')
        tags = response.text.split(",") if hasattr(response, 'text') else []
        return [tag.strip() for tag in tags if tag.strip()]
    except Exception as e:
        return []

# Function to save to CSV
def save_to_csv(video_data, filename="video_data.csv"):
    """Save data to CSV file"""
    fieldnames = [
        'id', 'user_id', 'title', 'channel_name', 'video_type',
        'tags', 'summary', 'thumbnail_url', 'original_url', 'date_added'
    ]
    
    file_exists = os.path.exists(filename)
    with open(filename, mode='a', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        print("Saving data:", video_data)  # Add debug logging
        writer.writerow(video_data)

# Add this new view to get CSRF token
def get_csrf_token(request):
    return JsonResponse({'csrfToken': get_token(request)})

# Add a simple test endpoint
@csrf_exempt
def test_connection(request):
    return JsonResponse({
        'status': 'success',
        'message': 'Connection successful!',
        'method': request.method,
        'host': request.get_host(),
        'remote_addr': request.META.get('REMOTE_ADDR'),
        'headers': dict(request.headers)
    })

# Add csrf_exempt decorator to the view
@csrf_exempt
def generate_keywords_and_summary(request):
    try:
        print(f"üì® Received {request.method} request to generate_keywords_and_summary")
        print(f"üîó Request path: {request.path}")
        print(f"üéØ Request headers: {dict(request.headers)}")
        
        if request.method == 'POST':
            data = json.loads(request.body)
            url = data.get('url')
            user_id = data.get('user_id')
            transcript = data.get('transcript')  # Get transcript from frontend
            print(f"üìù POST data: url={url}, user_id={user_id}")
        elif request.method == 'GET':
            # Handle GET requests from frontend
            url = request.GET.get('url')
            user_id = request.GET.get('user_id')
            transcript = None  # No transcript in GET request
            print(f"üìù GET params: url={url}, user_id={user_id}")
        else:
            return JsonResponse({"error": "Method not allowed"}, status=405)

        if not url or not user_id:
            print(f"‚ùå Missing data: url={url}, user_id={user_id}")
            return JsonResponse({"error": "Missing URL or user_id"}, status=400)        # Extract video details
        try:
            print(f"üé¨ Extracting video ID from URL: {url}")
            if 'youtu.be' in url:
                video_id = url.split('/')[-1].split('?')[0]
            elif 'youtube.com' in url:
                if 'v=' in url:
                    video_id = url.split('v=')[1].split('&')[0]
                elif '/shorts/' in url:
                    video_id = url.split('/shorts/')[-1].split('?')[0]
                else:
                    video_id = url.split('/')[-1]
            else:
                print(f"‚ùå Invalid YouTube URL format: {url}")
                return JsonResponse({"error": "Invalid YouTube URL format"}, status=400)
            
            print(f"‚úÖ Extracted video ID: {video_id}")
        except Exception as e:
            print(f"‚ùå URL parsing failed: {str(e)}")
            return JsonResponse({"error": f"URL parsing failed: {str(e)}"}, status=400)        # Fetch video details
        print(f"üîç Fetching YouTube video details for ID: {video_id}")
        title, channel_name, video_type, thumbnail_url = fetch_youtube_details(video_id)
        
        if not (title and channel_name and video_type):
            print(f"‚ùå Failed to get video information: title={title}, channel={channel_name}, type={video_type}")
            return JsonResponse({"error": "Failed to get video information"}, status=500)
        print(f"‚úÖ Video details: {title} by {channel_name}")

        # Use provided transcript or try to fetch from backend using improved logic
        if not transcript:
            print("üìù No transcript provided, trying to fetch from backend...")
            try:
                transcript_data = get_youtube_transcript(video_id)
                transcript = transcript_to_text(transcript_data)
                if transcript:
                    print(f"‚úÖ Transcript fetched: {len(transcript)} characters")
                else:
                    print("‚ùå No transcript found")
                    return JsonResponse({"error": "No transcript available"}, status=400)
            except Exception as e:
                print(f"‚ùå Backend transcript fetch failed: {e}")
                logger.error(f"Backend transcript fetch failed: {e}")
                return JsonResponse({"error": "No transcript available"}, status=400)
        else:
            print(f"‚úÖ Using provided transcript: {len(transcript)} characters")

        # Generate summary and tags using improved video understanding
        try:
            print("ü§ñ Generating summary and tags with video understanding...")
            summary = generate_summary_with_video(video_id, transcript)
            tags = generate_tags_with_video(video_id, transcript)
            print(f"‚úÖ Generated summary: {len(summary)} characters")
            print(f"‚úÖ Generated {len(tags)} tags")
        except Exception as e:
            print(f"‚ùå Error generating summary/tags: {e}")
            return JsonResponse({"error": "Failed to generate summary"}, status=500)

        content_data = {
            'id': generate_short_id(),
            'user_id': user_id,
            'title': title,
            'channel_name': channel_name,
            'video_type': video_type,
            'tags': ", ".join(tags),
            'summary': summary,
            'thumbnail_url': thumbnail_url,
            'original_url': url,
            'date_added': datetime.now().isoformat()
        }

        # Save to Supabase
        try:
            print("üíæ Saving to Supabase...")
            result = save_to_supabase(content_data)
            if not result:
                return JsonResponse({"error": "Failed to save to database"}, status=500)
            print("‚úÖ Successfully saved to Supabase")
        except Exception as e:
            print(f"‚ùå Error saving to Supabase: {e}")
            return JsonResponse({"error": "Failed to save data"}, status=500)

        return JsonResponse(content_data)

    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return JsonResponse({"error": str(e)}, status=500)